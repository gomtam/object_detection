# 통합 객체 인식 프로그램 코드 설명

## 프로그램 개요
이 프로그램은 YOLO(You Only Look Once) 딥러닝 모델을 활용하여 실시간으로 다양한 객체를 감지하는 시스템입니다. 웹캠 또는 화면 캡처를 입력 소스로 사용할 수 있으며, 사용자 선택에 따라 YOLOv3-tiny(빠른 처리) 또는 YOLOv3(정확한 감지) 모델을 적용할 수 있습니다. 또한 작은 객체 감지를 위한 특수 모드도 제공합니다.

## 주요 기능
1. **다양한 입력 소스 지원**: 화면 캡처 또는 웹캠(여러 웹캠 중 선택 가능)
2. **모델 선택 기능**: YOLOv3-tiny(빠름) 또는 YOLOv3(정확도 높음)
3. **작은 객체 감지 강화 모드**: 작은 객체에 대한 감지 성능 향상
4. **직관적인 사용자 인터페이스**: 대화형 메뉴 또는 명령줄 옵션으로 실행 가능
5. **실시간 성능 표시**: FPS(초당 프레임 수) 및 객체 감지 정보를 화면에 표시

## 코드 구조
프로그램은 다음과 같은 주요 함수들로 구성되어 있습니다:

1. `check_model_files()`: 필요한 모델 파일이 존재하는지 확인
2. `check_available_cameras()`: 사용 가능한 카메라 장치 검색
3. `show_menu()`: 사용자 인터페이스 메뉴 표시
4. `unified_object_detection()`: 객체 감지 주요 처리 로직
5. `main()`: 프로그램 진입점으로 명령행 인자 처리

## 가장 중요한 코드 부분: 객체 감지 및 처리 로직

프로그램의 핵심은 `unified_object_detection()` 함수에서 객체를 감지하고 결과를 처리하는 부분입니다. 특히 아래 코드 부분이 가장 중요합니다:

```python
# 탐지된 객체 정보 수집
for output in outputs:
    for detection in output:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]
        
        # 임계값 이상인 경우만 처리
        if confidence > confidence_threshold:
            # 객체 좌표 계산
            center_x = int(detection[0] * width)
            center_y = int(detection[1] * height)
            w = int(detection[2] * width)
            h = int(detection[3] * height)
            
            # 작은 객체 감지를 위한 크기 조정
            if small_detection and w * h < (width * height * 0.01):  # 전체 화면의 1% 미만
                confidence *= 1.2  # 작은 객체에 대한 신뢰도 가중치 부여
                confidence = min(confidence, 1.0)  # 1.0을 초과하지 않도록
            
            # 좌표 계산
            x = int(center_x - w / 2)
            y = int(center_y - h / 2)
            
            boxes.append([x, y, w, h])
            confidences.append(float(confidence))
            class_ids.append(class_id)
```

이 코드는 YOLO 모델의 출력 결과를 처리하여 객체를 감지하는 핵심 로직입니다. 구체적인 역할은 다음과 같습니다:

1. **모델 출력 처리**: YOLO 모델의 출력 레이어를 순회하며 각 감지 항목을 확인합니다.
2. **신뢰도(Confidence) 평가**: 각 객체 클래스의 점수(score)를 확인하고, 가장 높은 점수를 가진 클래스를 선택합니다.
3. **임계값 필터링**: 설정된 임계값보다 높은 신뢰도를 가진 객체만 처리합니다.
4. **객체 위치 계산**: 감지된 객체의 중심 좌표와 크기를 원본 이미지 크기에 맞게 변환합니다.
5. **작은 객체 처리 강화**: 작은 객체 감지 모드가 활성화된 경우, 작은 객체(전체 화면의 1% 미만)에 대해 신뢰도에 가중치를 부여합니다.
6. **결과 저장**: 각 객체의 좌표, 신뢰도, 클래스 ID를 배열에 저장하여 후속 처리를 위해 준비합니다.

이 코드에서 특히 주목할 부분은 작은 객체 감지를 위한 처리 로직입니다. 일반적인 객체 감지 모델은 작은 객체를 놓치기 쉽기 때문에, 이 프로그램은 작은 객체의 신뢰도에 가중치(1.2배)를 부여하여 감지 확률을 높입니다. 이는 작은 객체 감지가 중요한 상황(예: 원거리 카메라 감시, 세밀한 객체 구분 등)에서 유용합니다.

## 성능 최적화 및 사용성 개선 사항
- **프레임 스킵**: 처리 부하를 줄이기 위해 모든 프레임을 처리하지 않고 일부 프레임만 처리합니다.
- **GPU 가속**: CUDA가 사용 가능한 경우 GPU 가속을 활성화하여 처리 속도를 높입니다.
- **Non-maximum Suppression(NMS)**: 중복 감지를 제거하여 결과의 정확도를 향상시킵니다.
- **예외 처리**: 다양한 오류 상황(모델 파일 누락, 카메라 연결 실패 등)에 대한 예외 처리를 강화했습니다.
- **시각적 피드백**: 처리 상태와 결과를 실시간으로 화면에 표시하여 사용자에게 피드백을 제공합니다.

## 요약
이 객체 인식 프로그램은 YOLO 딥러닝 모델을 사용하여 다양한 환경(웹캠, 화면 캡처)에서 실시간 객체 감지를 수행합니다. 특히 작은 객체 감지를 위한 특별한 처리 로직을 통해 다양한 응용 분야에서 활용할 수 있습니다. 사용자 인터페이스와 다양한 옵션을 통해 사용자는 자신의 필요에 맞게 시스템을 구성할 수 있습니다. 